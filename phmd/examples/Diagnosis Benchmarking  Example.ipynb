{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4553fd1-4893-4c38-a518-305c81c6dfcf",
   "metadata": {},
   "source": [
    "# Diagnosis Benchmarking Example\n",
    "\n",
    "This notebook provides a comprehensive workflow for benchmarking machine learning models in the context of Prognostics and Health Management (PHM) using multiple datasets with the package `phmd`. The focus is on fault detection tasks. \n",
    "\n",
    "The following functions are utility functions used in the benchmarking loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32930ff5-abf2-47ba-aac5-428bf0e2ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phmd import datasets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def window_split(X, unit_id, signal_cols, target_col, subsignal_length=1000, signal_max_length=20000):\n",
    "    \"\"\"\n",
    "    Splits time-series data into fixed-length windows for training machine learning models.\n",
    "    \n",
    "    This function processes time-series data, splitting it into smaller, fixed-length segments (windows).\n",
    "    It ensures that each segment corresponds to a specific unit identified by the `unit_id` column\n",
    "    and aligns the target variable for each segment to the last value in the window. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas.DataFrame\n",
    "        The input dataset containing the time-series data.\n",
    "        Must include columns specified by `unit_id`, `signal_cols`, and `target_col`.\n",
    "    \n",
    "    unit_id : str\n",
    "        The name of the column in `X` used to identify individual units in the dataset.\n",
    "    \n",
    "    signal_cols : list of str\n",
    "        A list of column names in `X` representing the signal data (features) for each unit.\n",
    "    \n",
    "    target_col : str\n",
    "        The name of the column in `X` representing the target variable to predict.\n",
    "    \n",
    "    subsignal_length : int, optional, default=1000\n",
    "        The length of each window (number of time-steps) to extract from the signal.\n",
    "    \n",
    "    signal_max_length : int, optional, default=20000\n",
    "        The maximum number of time-steps to consider per unit.\n",
    "        Excess data is truncated from the beginning to fit within this limit.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy.ndarray\n",
    "        A 3D array of shape `(num_windows, subsignal_length, num_features)`, where:\n",
    "            - `num_windows` is the total number of extracted windows across all units.\n",
    "            - `subsignal_length` is the fixed length of each window.\n",
    "            - `num_features` is the number of signal features.\n",
    "    \n",
    "    Y : numpy.ndarray\n",
    "        A 1D array of shape `(num_windows,)` containing the target variable values\n",
    "        for each window, corresponding to the last time-step in the window.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'unit_id': [1, 1, 1, 2, 2, 2],\n",
    "    ...     'signal1': [0.1, 0.2, 0.3, 0.5, 0.6, 0.7],\n",
    "    ...     'signal2': [0.4, 0.5, 0.6, 0.8, 0.9, 1.0],\n",
    "    ...     'target': [10, 20, 30, 40, 50, 60]\n",
    "    ... })\n",
    "    >>> X, Y = window_split(df, 'unit_id', ['signal1', 'signal2'], 'target', subsignal_length=2, signal_max_length=4)\n",
    "    >>> print(X.shape)\n",
    "    (2, 2, 2)\n",
    "    >>> print(Y)\n",
    "    [20. 50.]\n",
    "    \"\"\"\n",
    "        \n",
    "    units_array = X[unit_id].values\n",
    "    signal_array = X[signal_cols].values\n",
    "    targets = X[target_col].values\n",
    "    N = signal_max_length // subsignal_length\n",
    "\n",
    "    num_units = X[unit_id].drop_duplicates().shape[0]\n",
    "    unique_units = X[unit_id].drop_duplicates().values\n",
    "    X = np.zeros((N * num_units, subsignal_length, len(signal_cols)))\n",
    "    Y = np.zeros((N * num_units,))\n",
    "    NN = 0\n",
    "    for i, unit in enumerate(unique_units):\n",
    "        mask = np.all(units_array == unit, axis=1)\n",
    "        signal = signal_array[mask]\n",
    "        sml = (signal.shape[0] // subsignal_length) * subsignal_length\n",
    "        n = min(sml // subsignal_length, N)\n",
    "        sml = subsignal_length * n\n",
    "        signal = signal[-sml:]\n",
    "        signal = signal.reshape((n, subsignal_length, len(signal_cols)))\n",
    "        signal_target = targets[mask][-sml:]\n",
    "        signal_target = signal_target.reshape((n, subsignal_length))\n",
    "        X[NN:NN + n] = signal\n",
    "        Y[NN:NN + n] = signal_target[:, -1]\n",
    "        NN += n\n",
    "\n",
    "    X = X[:NN]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def create_conv_1d_network(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    This function defines a 1D CNN architecture suitable for RUL tasks.\n",
    "    The model consists of multiple convolutional layers, followed by \n",
    "    max-pooling layers for feature extraction,  and dense layers for prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_shape : tuple\n",
    "        The shape of the input data (timesteps, features). This defines the dimensions \n",
    "        of the input layer.\n",
    "\n",
    "    num_classes : int\n",
    "        Number of classes of the target variable        \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tf.keras.Model\n",
    "        A compiled Keras Model with the defined architecture.\n",
    "    \"\"\"\n",
    "    # Define the input layer\n",
    "    input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # Initialize the input for stacking\n",
    "    x = input\n",
    "\n",
    "    # Add 4 blocks of convolutional and pooling layers\n",
    "    for i in range(4):\n",
    "        # Each block contains three Conv1D layers with 64 filters and a kernel size of 3\n",
    "        x = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "        # Add a MaxPooling1D layer to downsample the feature maps\n",
    "        x = tf.keras.layers.MaxPooling1D(2)(x)\n",
    "\n",
    "    # Flatten the feature maps to prepare for dense layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    # Fully connected layers for prediction\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    # Output layer: single neuron with ReLU activation (suitable for regression tasks)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create and return the Keras Model\n",
    "    return tf.keras.models.Model(inputs=input, outputs=x)\n",
    "\n",
    "\n",
    "\n",
    "def train(train_data, num_classes, epochs, es=True, validation_data=None):\n",
    "    \"\"\"\n",
    "    This function trains a 1D convolutional neural network using the provided training data and \n",
    "    optional validation data. It employs early stopping during training and performs an initial \n",
    "    sanity check to ensure that the training loss evolves correctly before proceeding with full training.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : tuple\n",
    "        A tuple `(X_train, Y_train)` containing the training data:\n",
    "            - `X_train` : numpy.ndarray\n",
    "                Input features for training (shape: `(num_samples, timesteps, features)`).\n",
    "            - `Y_train` : numpy.ndarray\n",
    "                Target values for training (shape: `(num_samples,)`).\n",
    "    \n",
    "    num_classes : int\n",
    "        Number of classes of the target variable\n",
    "        \n",
    "    epochs : int\n",
    "        Number of epochs for the final training phase.\n",
    "    \n",
    "    es : bool, optional, default=True\n",
    "        If `True`, early stopping is applied during training. Early stopping monitors the validation loss \n",
    "        and stops training if the loss does not improve for 8 consecutive epochs.\n",
    "    \n",
    "    validation_data : tuple, optional, default=None\n",
    "        A tuple `(X_val, Y_val)` containing validation data:\n",
    "            - `X_val` : numpy.ndarray\n",
    "                Input features for validation.\n",
    "            - `Y_val` : numpy.ndarray\n",
    "                Target values for validation.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : History\n",
    "        A Keras History object containing details about the training process, including loss and metric values.\n",
    "    \n",
    "    model : tf.keras.Model\n",
    "        The trained model.\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> train_data = (X_train, Y_train)\n",
    "    >>> validation_data = (X_val, Y_val)\n",
    "    >>> results, model = train(train_data, epochs=50, validation_data=validation_data)\n",
    "    \"\"\"    \n",
    "    # Unpack training data\n",
    "    X_train, Y_train = train_data\n",
    "\n",
    "    # Configure callbacks for early stopping if enabled\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)] if es else []\n",
    "\n",
    "    valid_train = False\n",
    "    while not valid_train:\n",
    "        # Create and compile the model\n",
    "        model = create_conv_1d_network(X_train.shape[1:], num_classes)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), \n",
    "                      metrics=['accuracy'], \n",
    "                      loss='sparse_categorical_crossentropy')\n",
    "\n",
    "        # Perform an initial short training session (3 epochs) to validate training behavior\n",
    "        results = model.fit(X_train, Y_train,\n",
    "                            epochs=3,\n",
    "                            batch_size=128,\n",
    "                            verbose=1,\n",
    "                            validation_data=validation_data,\n",
    "                            callbacks=callbacks)\n",
    "\n",
    "        # Check if the loss has sufficient variance to ensure proper learning\n",
    "        valid_train = np.std(results.history['loss']) > 1e-6\n",
    "\n",
    "    # Perform full training with the specified number of epochs\n",
    "    results = model.fit(X_train, Y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=128,\n",
    "                        verbose=1,\n",
    "                        validation_data=validation_data,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    return results, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b735d-db3c-4e4e-a47f-3b960dd987a4",
   "metadata": {},
   "source": [
    "## Benchmarking Loop\n",
    "\n",
    "For this example have been selecte three small dataset: `NMILL`, `CWRU`, and `KAUG17`.\n",
    "\n",
    "The `datasets.Dataset` class is used to load and manage datasets.\n",
    "\n",
    "This example implements a 3-fold cross-validation setup and MinMaxScaler to normalize input features. Defines a 1D Convolutional Neural Network (Conv1D) using TensorFlow/Keras. The architecture includes multiple convolutional layers followed by dense layers, optimized for time-series data.\n",
    "\n",
    "After cross-validation, a final model is trained on the combined training and validation data for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a7e44e0-9020-447e-a49e-c25108070cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset NMILL already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t@misc{nasaPrognosticsCenter,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {{P}rognostics {C}enter of {E}xcellence {D}ata {S}et {R}epository - {N}{A}{S}{A} --- nasa.gov},\n",
      "\t\thowpublished = {\\url{https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\n",
      "You can download the dataset manually from:  https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#milling\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.85s/it]\n",
      "/home/dasolma/miniconda3/envs/phm_framework_gpu/lib/python3.9/site-packages/phmd/readers/nmill.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"unit\"] = X.unit.astype('int').astype('str') + \"_\" + X.CBM.astype('str')\n",
      "INFO:root:Read in 12.520188331604004 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: AE_spindle,vib_table,AE_table,unit,smcDC,CBM,smcAC,vib_spindle\n",
      "INFO:root:Train shape: (692489, 8)\n",
      "INFO:root:Val shape: (434995, 8)\n",
      "INFO:root:Test shape: (114514, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 1s 132ms/step - loss: 1.0982 - accuracy: 0.4429 - val_loss: 1.0977 - val_accuracy: 0.4000\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0969 - accuracy: 0.4297 - val_loss: 1.0967 - val_accuracy: 0.3950\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.0953 - accuracy: 0.4400 - val_loss: 1.0952 - val_accuracy: 0.4000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0928 - accuracy: 0.4444 - val_loss: 1.0934 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0899 - accuracy: 0.4444 - val_loss: 1.0910 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0859 - accuracy: 0.4444 - val_loss: 1.0878 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0803 - accuracy: 0.4444 - val_loss: 1.0834 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0719 - accuracy: 0.4444 - val_loss: 1.0777 - val_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0612 - accuracy: 0.4444 - val_loss: 1.0710 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0477 - accuracy: 0.4444 - val_loss: 1.0639 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0302 - accuracy: 0.4444 - val_loss: 1.0589 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0110 - accuracy: 0.4444 - val_loss: 1.0613 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9897 - accuracy: 0.4444 - val_loss: 1.0792 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9796 - accuracy: 0.4444 - val_loss: 1.1144 - val_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9722 - accuracy: 0.4444 - val_loss: 1.1380 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9647 - accuracy: 0.4444 - val_loss: 1.1377 - val_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9559 - accuracy: 0.4444 - val_loss: 1.1347 - val_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9530 - accuracy: 0.4444 - val_loss: 1.1305 - val_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9505 - accuracy: 0.4444 - val_loss: 1.1370 - val_accuracy: 0.4000\n",
      "Dataset NMILL already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t@misc{nasaPrognosticsCenter,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {{P}rognostics {C}enter of {E}xcellence {D}ata {S}et {R}epository - {N}{A}{S}{A} --- nasa.gov},\n",
      "\t\thowpublished = {\\url{https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\n",
      "You can download the dataset manually from:  https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#milling\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.02s/it]\n",
      "/home/dasolma/miniconda3/envs/phm_framework_gpu/lib/python3.9/site-packages/phmd/readers/nmill.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"unit\"] = X.unit.astype('int').astype('str') + \"_\" + X.CBM.astype('str')\n",
      "INFO:root:Read in 11.741857051849365 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: AE_spindle,vib_table,AE_table,unit,smcDC,CBM,smcAC,vib_spindle\n",
      "INFO:root:Train shape: (781748, 8)\n",
      "INFO:root:Val shape: (345736, 8)\n",
      "INFO:root:Test shape: (114514, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 1s 141ms/step - loss: 1.0992 - accuracy: 0.1914 - val_loss: 1.0985 - val_accuracy: 0.4444\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0983 - accuracy: 0.4088 - val_loss: 1.0981 - val_accuracy: 0.4444\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0978 - accuracy: 0.4234 - val_loss: 1.0979 - val_accuracy: 0.4444\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.0973 - accuracy: 0.4211 - val_loss: 1.0976 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0966 - accuracy: 0.4211 - val_loss: 1.0972 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0957 - accuracy: 0.4553 - val_loss: 1.0968 - val_accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0944 - accuracy: 0.5789 - val_loss: 1.0963 - val_accuracy: 0.4611\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0928 - accuracy: 0.6474 - val_loss: 1.0956 - val_accuracy: 0.4778\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0906 - accuracy: 0.6316 - val_loss: 1.0945 - val_accuracy: 0.4889\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0880 - accuracy: 0.6553 - val_loss: 1.0932 - val_accuracy: 0.4833\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0841 - accuracy: 0.6421 - val_loss: 1.0915 - val_accuracy: 0.4889\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0791 - accuracy: 0.6368 - val_loss: 1.0894 - val_accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0723 - accuracy: 0.6553 - val_loss: 1.0864 - val_accuracy: 0.4778\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0627 - accuracy: 0.6368 - val_loss: 1.0826 - val_accuracy: 0.4778\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0500 - accuracy: 0.6105 - val_loss: 1.0777 - val_accuracy: 0.4778\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0325 - accuracy: 0.6237 - val_loss: 1.0719 - val_accuracy: 0.4833\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0087 - accuracy: 0.6105 - val_loss: 1.0637 - val_accuracy: 0.4778\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9794 - accuracy: 0.6368 - val_loss: 1.0558 - val_accuracy: 0.4722\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9483 - accuracy: 0.6316 - val_loss: 1.0443 - val_accuracy: 0.4611\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9107 - accuracy: 0.6816 - val_loss: 1.0255 - val_accuracy: 0.4278\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8754 - accuracy: 0.6947 - val_loss: 1.0219 - val_accuracy: 0.4278\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8375 - accuracy: 0.6921 - val_loss: 0.9814 - val_accuracy: 0.5111\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8041 - accuracy: 0.7026 - val_loss: 0.9820 - val_accuracy: 0.4833\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7643 - accuracy: 0.7079 - val_loss: 0.9661 - val_accuracy: 0.5500\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7291 - accuracy: 0.7237 - val_loss: 0.9797 - val_accuracy: 0.5111\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7118 - accuracy: 0.7158 - val_loss: 0.9762 - val_accuracy: 0.5556\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6804 - accuracy: 0.7263 - val_loss: 0.9837 - val_accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6619 - accuracy: 0.7474 - val_loss: 0.9750 - val_accuracy: 0.6278\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6511 - accuracy: 0.7500 - val_loss: 1.0135 - val_accuracy: 0.5444\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6517 - accuracy: 0.7368 - val_loss: 0.9931 - val_accuracy: 0.6111\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6244 - accuracy: 0.7342 - val_loss: 1.0048 - val_accuracy: 0.6056\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6135 - accuracy: 0.7395 - val_loss: 0.9892 - val_accuracy: 0.6167\n",
      "Dataset NMILL already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t@misc{nasaPrognosticsCenter,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {{P}rognostics {C}enter of {E}xcellence {D}ata {S}et {R}epository - {N}{A}{S}{A} --- nasa.gov},\n",
      "\t\thowpublished = {\\url{https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\n",
      "You can download the dataset manually from:  https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#milling\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.40s/it]\n",
      "/home/dasolma/miniconda3/envs/phm_framework_gpu/lib/python3.9/site-packages/phmd/readers/nmill.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"unit\"] = X.unit.astype('int').astype('str') + \"_\" + X.CBM.astype('str')\n",
      "INFO:root:Read in 12.145414590835571 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: AE_spindle,vib_table,AE_table,unit,smcDC,CBM,smcAC,vib_spindle\n",
      "INFO:root:Train shape: (780731, 8)\n",
      "INFO:root:Val shape: (346753, 8)\n",
      "INFO:root:Test shape: (114514, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 1s 145ms/step - loss: 1.0980 - accuracy: 0.4015 - val_loss: 1.0960 - val_accuracy: 0.4444\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0961 - accuracy: 0.4224 - val_loss: 1.0936 - val_accuracy: 0.4444\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0944 - accuracy: 0.4195 - val_loss: 1.0907 - val_accuracy: 0.4444\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.0915 - accuracy: 0.4211 - val_loss: 1.0873 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0886 - accuracy: 0.4211 - val_loss: 1.0826 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0843 - accuracy: 0.4211 - val_loss: 1.0761 - val_accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0795 - accuracy: 0.4211 - val_loss: 1.0675 - val_accuracy: 0.4444\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0721 - accuracy: 0.4211 - val_loss: 1.0561 - val_accuracy: 0.4444\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0635 - accuracy: 0.4211 - val_loss: 1.0417 - val_accuracy: 0.4444\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0544 - accuracy: 0.4211 - val_loss: 1.0240 - val_accuracy: 0.4444\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.0446 - accuracy: 0.4211 - val_loss: 1.0063 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0367 - accuracy: 0.4211 - val_loss: 0.9921 - val_accuracy: 0.4444\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0324 - accuracy: 0.4211 - val_loss: 0.9847 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0296 - accuracy: 0.4211 - val_loss: 0.9804 - val_accuracy: 0.4444\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0233 - accuracy: 0.4211 - val_loss: 0.9838 - val_accuracy: 0.4444\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0185 - accuracy: 0.4211 - val_loss: 0.9854 - val_accuracy: 0.4444\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0138 - accuracy: 0.4211 - val_loss: 0.9829 - val_accuracy: 0.4444\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0091 - accuracy: 0.4211 - val_loss: 0.9768 - val_accuracy: 0.4444\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0038 - accuracy: 0.4211 - val_loss: 0.9775 - val_accuracy: 0.4444\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9980 - accuracy: 0.4211 - val_loss: 0.9762 - val_accuracy: 0.4444\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9899 - accuracy: 0.4211 - val_loss: 0.9679 - val_accuracy: 0.4444\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9839 - accuracy: 0.4211 - val_loss: 0.9693 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9754 - accuracy: 0.4211 - val_loss: 0.9760 - val_accuracy: 0.4444\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9625 - accuracy: 0.4211 - val_loss: 0.9639 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9545 - accuracy: 0.4211 - val_loss: 0.9631 - val_accuracy: 0.4444\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9365 - accuracy: 0.4211 - val_loss: 0.9735 - val_accuracy: 0.4444\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9240 - accuracy: 0.4211 - val_loss: 0.9559 - val_accuracy: 0.6722\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9070 - accuracy: 0.4868 - val_loss: 0.9524 - val_accuracy: 0.6500\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8865 - accuracy: 0.6053 - val_loss: 0.9468 - val_accuracy: 0.6389\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8667 - accuracy: 0.6368 - val_loss: 0.9329 - val_accuracy: 0.6333\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8433 - accuracy: 0.7158 - val_loss: 0.9273 - val_accuracy: 0.6333\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8161 - accuracy: 0.7263 - val_loss: 0.9111 - val_accuracy: 0.6278\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7941 - accuracy: 0.7658 - val_loss: 0.8961 - val_accuracy: 0.6333\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7687 - accuracy: 0.7474 - val_loss: 0.8814 - val_accuracy: 0.6556\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7388 - accuracy: 0.7711 - val_loss: 0.8598 - val_accuracy: 0.6278\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7095 - accuracy: 0.7684 - val_loss: 0.8384 - val_accuracy: 0.6556\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6819 - accuracy: 0.7684 - val_loss: 0.8288 - val_accuracy: 0.6611\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6659 - accuracy: 0.7605 - val_loss: 0.8110 - val_accuracy: 0.6611\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6339 - accuracy: 0.7632 - val_loss: 0.8117 - val_accuracy: 0.6611\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6126 - accuracy: 0.7579 - val_loss: 0.8151 - val_accuracy: 0.6611\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6042 - accuracy: 0.7605 - val_loss: 0.8297 - val_accuracy: 0.6611\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5790 - accuracy: 0.7474 - val_loss: 0.8672 - val_accuracy: 0.6722\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5819 - accuracy: 0.7711 - val_loss: 0.8588 - val_accuracy: 0.6611\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5557 - accuracy: 0.7842 - val_loss: 0.8974 - val_accuracy: 0.6722\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5552 - accuracy: 0.7763 - val_loss: 0.8790 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5708 - accuracy: 0.7737 - val_loss: 0.9164 - val_accuracy: 0.6722\n",
      "Epoch 1/3\n",
      "5/5 [==============================] - 1s 6ms/step - loss: 1.0967 - accuracy: 0.4398\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0930 - accuracy: 0.4381\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0876 - accuracy: 0.4800\n",
      "Epoch 1/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0773 - accuracy: 0.4911\n",
      "Epoch 2/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0637 - accuracy: 0.4268\n",
      "Epoch 3/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0431 - accuracy: 0.4268\n",
      "Epoch 4/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0170 - accuracy: 0.4286\n",
      "Epoch 5/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0022 - accuracy: 0.4286\n",
      "Epoch 6/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "Epoch 7/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0010 - accuracy: 0.4286\n",
      "Epoch 8/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9963 - accuracy: 0.4286\n",
      "Epoch 9/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9943 - accuracy: 0.4286\n",
      "Epoch 10/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9905 - accuracy: 0.4304\n",
      "Epoch 11/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9850 - accuracy: 0.4304\n",
      "Epoch 12/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9762 - accuracy: 0.4946\n",
      "Epoch 13/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9648 - accuracy: 0.6125\n",
      "Epoch 14/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9488 - accuracy: 0.6214\n",
      "Epoch 15/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9271 - accuracy: 0.6232\n",
      "Epoch 16/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9019 - accuracy: 0.6679\n",
      "Epoch 17/29\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8759 - accuracy: 0.6304\n",
      "Epoch 18/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8480 - accuracy: 0.6643\n",
      "Epoch 19/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8255 - accuracy: 0.6607\n",
      "Epoch 20/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8112 - accuracy: 0.6571\n",
      "Epoch 21/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7928 - accuracy: 0.6750\n",
      "Epoch 22/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7773 - accuracy: 0.6536\n",
      "Epoch 23/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7590 - accuracy: 0.6821\n",
      "Epoch 24/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7437 - accuracy: 0.6875\n",
      "Epoch 25/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7384 - accuracy: 0.6554\n",
      "Epoch 26/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7293 - accuracy: 0.6643\n",
      "Epoch 27/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7207 - accuracy: 0.6946\n",
      "Epoch 28/29\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.6625\n",
      "Epoch 29/29\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7144 - accuracy: 0.6804\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0627 - accuracy: 0.5333\n",
      "Dataset CWRU already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t@misc{caseBearingData,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {{B}earing {D}ata {C}enter | {C}ase {S}chool of {E}ngineering | {C}ase {W}estern {R}eserve {U}niversity --- engineering.case.edu},\n",
      "\t\thowpublished = {\\url{https://engineering.case.edu/bearingdatacenter}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\n",
      "You can download the dataset manually from:  https://engineering.case.edu/bearingdatacenter\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [00:07<00:00, 22.66it/s]\n",
      "INFO:root:Read in 12.443865776062012 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: DE,unit,fault\n",
      "INFO:root:Train shape: (23576592, 3)\n",
      "INFO:root:Val shape: (12795426, 3)\n",
      "INFO:root:Test shape: (979629, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "51/51 [==============================] - 3s 37ms/step - loss: 1.3539 - accuracy: 0.4393 - val_loss: 1.2316 - val_accuracy: 0.4717\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1822 - accuracy: 0.4811 - val_loss: 1.1810 - val_accuracy: 0.4717\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1356 - accuracy: 0.4721 - val_loss: 1.1814 - val_accuracy: 0.4717\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1226 - accuracy: 0.4808 - val_loss: 1.1869 - val_accuracy: 0.4717\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1234 - accuracy: 0.4808 - val_loss: 1.1749 - val_accuracy: 0.4717\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1213 - accuracy: 0.4808 - val_loss: 1.1785 - val_accuracy: 0.4717\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1210 - accuracy: 0.4808 - val_loss: 1.1694 - val_accuracy: 0.4717\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1206 - accuracy: 0.4808 - val_loss: 1.1751 - val_accuracy: 0.4717\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1200 - accuracy: 0.4808 - val_loss: 1.1764 - val_accuracy: 0.4717\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1183 - accuracy: 0.4808 - val_loss: 1.1817 - val_accuracy: 0.4717\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1182 - accuracy: 0.4808 - val_loss: 1.1721 - val_accuracy: 0.4717\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1088 - accuracy: 0.4808 - val_loss: 1.1661 - val_accuracy: 0.4717\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.0701 - accuracy: 0.4808 - val_loss: 1.1618 - val_accuracy: 0.4717\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.0444 - accuracy: 0.4815 - val_loss: 1.1508 - val_accuracy: 0.4717\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.0090 - accuracy: 0.5202 - val_loss: 1.1405 - val_accuracy: 0.4020\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.9619 - accuracy: 0.5609 - val_loss: 1.0974 - val_accuracy: 0.4537\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.8659 - accuracy: 0.5989 - val_loss: 1.0420 - val_accuracy: 0.5037\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.8163 - accuracy: 0.6127 - val_loss: 1.0004 - val_accuracy: 0.4811\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7634 - accuracy: 0.6307 - val_loss: 0.9694 - val_accuracy: 0.5216\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.7325 - accuracy: 0.6486 - val_loss: 0.9474 - val_accuracy: 0.5271\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.7013 - accuracy: 0.6655 - val_loss: 1.0320 - val_accuracy: 0.5490\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6933 - accuracy: 0.6709 - val_loss: 0.9201 - val_accuracy: 0.5429\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6552 - accuracy: 0.6953 - val_loss: 0.9110 - val_accuracy: 0.5456\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6388 - accuracy: 0.7070 - val_loss: 1.1057 - val_accuracy: 0.5173\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6173 - accuracy: 0.7199 - val_loss: 0.9185 - val_accuracy: 0.5682\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.5831 - accuracy: 0.7367 - val_loss: 0.9455 - val_accuracy: 0.5752\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5597 - accuracy: 0.7486 - val_loss: 0.9450 - val_accuracy: 0.5721\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5476 - accuracy: 0.7516 - val_loss: 1.0047 - val_accuracy: 0.5764\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.5688 - accuracy: 0.7429 - val_loss: 0.8633 - val_accuracy: 0.5816\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5309 - accuracy: 0.7564 - val_loss: 0.8666 - val_accuracy: 0.5989\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5480 - accuracy: 0.7483 - val_loss: 0.9790 - val_accuracy: 0.5767\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5057 - accuracy: 0.7712 - val_loss: 0.8482 - val_accuracy: 0.6138\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4914 - accuracy: 0.7771 - val_loss: 0.9501 - val_accuracy: 0.6059\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4857 - accuracy: 0.7775 - val_loss: 0.9094 - val_accuracy: 0.6074\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4785 - accuracy: 0.7854 - val_loss: 0.9106 - val_accuracy: 0.6147\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.4745 - accuracy: 0.7916 - val_loss: 0.9813 - val_accuracy: 0.6053\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4678 - accuracy: 0.7967 - val_loss: 0.8947 - val_accuracy: 0.6382\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.4726 - accuracy: 0.7975 - val_loss: 0.9508 - val_accuracy: 0.6251\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4478 - accuracy: 0.8051 - val_loss: 0.8973 - val_accuracy: 0.6488\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4492 - accuracy: 0.8063 - val_loss: 0.8180 - val_accuracy: 0.6439\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.4349 - accuracy: 0.8133 - val_loss: 0.9080 - val_accuracy: 0.6555\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4398 - accuracy: 0.8100 - val_loss: 0.9203 - val_accuracy: 0.6564\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4283 - accuracy: 0.8141 - val_loss: 0.9142 - val_accuracy: 0.6586\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4299 - accuracy: 0.8142 - val_loss: 1.0275 - val_accuracy: 0.6427\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.4185 - accuracy: 0.8179 - val_loss: 0.8796 - val_accuracy: 0.6388\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.4562 - accuracy: 0.7979 - val_loss: 1.1034 - val_accuracy: 0.6446\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.4358 - accuracy: 0.8106 - val_loss: 0.9454 - val_accuracy: 0.6372\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4103 - accuracy: 0.8254 - val_loss: 0.9058 - val_accuracy: 0.6150\n",
      "Dataset CWRU already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t@misc{caseBearingData,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {{B}earing {D}ata {C}enter | {C}ase {S}chool of {E}ngineering | {C}ase {W}estern {R}eserve {U}niversity --- engineering.case.edu},\n",
      "\t\thowpublished = {\\url{https://engineering.case.edu/bearingdatacenter}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\n",
      "You can download the dataset manually from:  https://engineering.case.edu/bearingdatacenter\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [00:06<00:00, 24.44it/s]\n",
      "INFO:root:Read in 11.896779537200928 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: DE,unit,fault\n",
      "INFO:root:Train shape: (24122964, 3)\n",
      "INFO:root:Val shape: (12249054, 3)\n",
      "INFO:root:Test shape: (979629, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "51/51 [==============================] - 3s 34ms/step - loss: 1.3463 - accuracy: 0.4442 - val_loss: 1.1587 - val_accuracy: 0.4808\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1557 - accuracy: 0.4755 - val_loss: 1.1222 - val_accuracy: 0.4808\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1488 - accuracy: 0.4743 - val_loss: 1.1250 - val_accuracy: 0.4808\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1471 - accuracy: 0.4762 - val_loss: 1.1246 - val_accuracy: 0.4808\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1469 - accuracy: 0.4762 - val_loss: 1.1277 - val_accuracy: 0.4808\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1478 - accuracy: 0.4762 - val_loss: 1.1224 - val_accuracy: 0.4808\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1476 - accuracy: 0.4762 - val_loss: 1.1214 - val_accuracy: 0.4808\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1469 - accuracy: 0.4762 - val_loss: 1.1248 - val_accuracy: 0.4808\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1477 - accuracy: 0.4762 - val_loss: 1.1280 - val_accuracy: 0.4808\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1201 - accuracy: 0.4986 - val_loss: 1.1308 - val_accuracy: 0.4808\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0938 - accuracy: 0.5140 - val_loss: 1.1274 - val_accuracy: 0.4808\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0843 - accuracy: 0.5135 - val_loss: 1.1255 - val_accuracy: 0.4808\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.0564 - accuracy: 0.5138 - val_loss: 1.1122 - val_accuracy: 0.4808\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0396 - accuracy: 0.5143 - val_loss: 1.0915 - val_accuracy: 0.4808\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 1s 30ms/step - loss: 1.0174 - accuracy: 0.5143 - val_loss: 1.0733 - val_accuracy: 0.4808\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0073 - accuracy: 0.5143 - val_loss: 1.0584 - val_accuracy: 0.4808\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.9837 - accuracy: 0.5095 - val_loss: 1.0275 - val_accuracy: 0.4808\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.9808 - accuracy: 0.5187 - val_loss: 1.1232 - val_accuracy: 0.4808\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0872 - accuracy: 0.5141 - val_loss: 1.1215 - val_accuracy: 0.4808\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0328 - accuracy: 0.5135 - val_loss: 1.0563 - val_accuracy: 0.4808\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0139 - accuracy: 0.5158 - val_loss: 1.0575 - val_accuracy: 0.4808\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.9706 - accuracy: 0.5226 - val_loss: 1.0226 - val_accuracy: 0.4944\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.9301 - accuracy: 0.5346 - val_loss: 1.0552 - val_accuracy: 0.4839\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.9054 - accuracy: 0.5496 - val_loss: 1.0053 - val_accuracy: 0.4668\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.8572 - accuracy: 0.5760 - val_loss: 0.8986 - val_accuracy: 0.5565\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.8193 - accuracy: 0.6068 - val_loss: 0.8758 - val_accuracy: 0.5679\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8715 - accuracy: 0.5700 - val_loss: 0.8993 - val_accuracy: 0.5630\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.8623 - accuracy: 0.5673 - val_loss: 1.0082 - val_accuracy: 0.4957\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.8243 - accuracy: 0.6018 - val_loss: 0.8622 - val_accuracy: 0.5884\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.7877 - accuracy: 0.6252 - val_loss: 0.8361 - val_accuracy: 0.5946\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.8151 - accuracy: 0.6009 - val_loss: 0.9376 - val_accuracy: 0.5493\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.8103 - accuracy: 0.6075 - val_loss: 0.8269 - val_accuracy: 0.5977\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.7604 - accuracy: 0.6336 - val_loss: 0.8118 - val_accuracy: 0.6275\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7739 - accuracy: 0.6296 - val_loss: 0.8955 - val_accuracy: 0.5313\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7683 - accuracy: 0.6293 - val_loss: 0.8102 - val_accuracy: 0.6362\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7563 - accuracy: 0.6481 - val_loss: 0.7939 - val_accuracy: 0.6371\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7362 - accuracy: 0.6479 - val_loss: 0.7704 - val_accuracy: 0.6163\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6872 - accuracy: 0.6748 - val_loss: 0.7424 - val_accuracy: 0.5639\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6963 - accuracy: 0.6751 - val_loss: 0.7473 - val_accuracy: 0.6120\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6845 - accuracy: 0.6739 - val_loss: 0.7835 - val_accuracy: 0.6138\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6395 - accuracy: 0.6888 - val_loss: 0.7233 - val_accuracy: 0.5850\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6354 - accuracy: 0.6952 - val_loss: 0.8645 - val_accuracy: 0.5853\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6390 - accuracy: 0.6889 - val_loss: 0.7216 - val_accuracy: 0.6594\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6522 - accuracy: 0.6942 - val_loss: 0.7726 - val_accuracy: 0.6238\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6161 - accuracy: 0.7135 - val_loss: 0.7863 - val_accuracy: 0.6067\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 1s 30ms/step - loss: 0.5738 - accuracy: 0.7187 - val_loss: 0.6871 - val_accuracy: 0.6191\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5496 - accuracy: 0.7378 - val_loss: 0.7686 - val_accuracy: 0.6507\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5298 - accuracy: 0.7530 - val_loss: 0.7729 - val_accuracy: 0.6148\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.5628 - accuracy: 0.7418 - val_loss: 1.0261 - val_accuracy: 0.4501\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6187 - accuracy: 0.7126 - val_loss: 0.7055 - val_accuracy: 0.6194\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 1s 30ms/step - loss: 0.5267 - accuracy: 0.7575 - val_loss: 0.7149 - val_accuracy: 0.6495\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.5174 - accuracy: 0.7650 - val_loss: 0.7225 - val_accuracy: 0.6476\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4740 - accuracy: 0.7849 - val_loss: 0.6927 - val_accuracy: 0.6743\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.4436 - accuracy: 0.7932 - val_loss: 0.6917 - val_accuracy: 0.6632\n",
      "Dataset CWRU already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t@misc{caseBearingData,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {{B}earing {D}ata {C}enter | {C}ase {S}chool of {E}ngineering | {C}ase {W}estern {R}eserve {U}niversity --- engineering.case.edu},\n",
      "\t\thowpublished = {\\url{https://engineering.case.edu/bearingdatacenter}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\n",
      "You can download the dataset manually from:  https://engineering.case.edu/bearingdatacenter\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [00:06<00:00, 25.51it/s]\n",
      "INFO:root:Read in 11.63110089302063 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: DE,unit,fault\n",
      "INFO:root:Train shape: (25044480, 3)\n",
      "INFO:root:Val shape: (11327538, 3)\n",
      "INFO:root:Test shape: (979629, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "51/51 [==============================] - 3s 34ms/step - loss: 1.3363 - accuracy: 0.4520 - val_loss: 1.1462 - val_accuracy: 0.4808\n",
      "Epoch 2/3\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1517 - accuracy: 0.4788 - val_loss: 1.1233 - val_accuracy: 0.4808\n",
      "Epoch 3/3\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1397 - accuracy: 0.4830 - val_loss: 1.1274 - val_accuracy: 0.4808\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1480 - accuracy: 0.4762 - val_loss: 1.1237 - val_accuracy: 0.4808\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1482 - accuracy: 0.4762 - val_loss: 1.1216 - val_accuracy: 0.4808\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1460 - accuracy: 0.4762 - val_loss: 1.1204 - val_accuracy: 0.4808\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1446 - accuracy: 0.4762 - val_loss: 1.1189 - val_accuracy: 0.4811\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.1244 - accuracy: 0.5012 - val_loss: 1.0961 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1080 - accuracy: 0.5048 - val_loss: 1.0993 - val_accuracy: 0.4994\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1.1015 - accuracy: 0.5043 - val_loss: 1.0733 - val_accuracy: 0.4957\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0759 - accuracy: 0.5038 - val_loss: 1.0302 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0648 - accuracy: 0.5045 - val_loss: 0.9825 - val_accuracy: 0.4994\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0063 - accuracy: 0.5118 - val_loss: 0.9056 - val_accuracy: 0.5326\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.9219 - accuracy: 0.5401 - val_loss: 0.8872 - val_accuracy: 0.5509\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8893 - accuracy: 0.5387 - val_loss: 0.9973 - val_accuracy: 0.5130\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8851 - accuracy: 0.5521 - val_loss: 0.8905 - val_accuracy: 0.5565\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.8325 - accuracy: 0.5674 - val_loss: 0.8928 - val_accuracy: 0.6123\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8162 - accuracy: 0.5919 - val_loss: 0.8130 - val_accuracy: 0.6340\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8325 - accuracy: 0.5822 - val_loss: 0.9011 - val_accuracy: 0.6414\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.8009 - accuracy: 0.5991 - val_loss: 0.8396 - val_accuracy: 0.6259\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7795 - accuracy: 0.6089 - val_loss: 0.8029 - val_accuracy: 0.5806\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 0.8067 - accuracy: 0.5989 - val_loss: 0.8202 - val_accuracy: 0.6045\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.7758 - accuracy: 0.6167 - val_loss: 0.7986 - val_accuracy: 0.5744\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.8395 - accuracy: 0.5969 - val_loss: 0.8072 - val_accuracy: 0.6272\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 2s 29ms/step - loss: 0.7218 - accuracy: 0.6564 - val_loss: 0.8010 - val_accuracy: 0.6194\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.7456 - accuracy: 0.6376 - val_loss: 1.0965 - val_accuracy: 0.5502\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6826 - accuracy: 0.6856 - val_loss: 0.7917 - val_accuracy: 0.6002\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.7487 - accuracy: 0.6453 - val_loss: 0.7694 - val_accuracy: 0.6067\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.9053 - accuracy: 0.6000 - val_loss: 1.0009 - val_accuracy: 0.4696\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 1.0294 - accuracy: 0.5098 - val_loss: 0.9638 - val_accuracy: 0.5109\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.9640 - accuracy: 0.5312 - val_loss: 0.9961 - val_accuracy: 0.5533\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.7782 - accuracy: 0.6094 - val_loss: 0.8126 - val_accuracy: 0.6098\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6778 - accuracy: 0.6925 - val_loss: 0.7841 - val_accuracy: 0.6545\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.6716 - accuracy: 0.6873 - val_loss: 0.7621 - val_accuracy: 0.6222\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.5938 - accuracy: 0.7301 - val_loss: 0.7841 - val_accuracy: 0.6185\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.6905 - accuracy: 0.6657 - val_loss: 0.8659 - val_accuracy: 0.6449\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.6282 - accuracy: 0.7149 - val_loss: 0.7748 - val_accuracy: 0.6402\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.5577 - accuracy: 0.7441 - val_loss: 0.7923 - val_accuracy: 0.6377\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 0.5755 - accuracy: 0.7273 - val_loss: 0.8217 - val_accuracy: 0.6297\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 0.5264 - accuracy: 0.7564 - val_loss: 0.8521 - val_accuracy: 0.6393\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 0.5371 - accuracy: 0.7510 - val_loss: 0.8165 - val_accuracy: 0.6514\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 0.5306 - accuracy: 0.7550 - val_loss: 0.7932 - val_accuracy: 0.6697\n",
      "Epoch 1/3\n",
      "77/77 [==============================] - 3s 24ms/step - loss: 1.3013 - accuracy: 0.4638\n",
      "Epoch 2/3\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 1.1374 - accuracy: 0.4789\n",
      "Epoch 3/3\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 1.1426 - accuracy: 0.4758\n",
      "Epoch 1/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 1.1400 - accuracy: 0.4777\n",
      "Epoch 2/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 1.1403 - accuracy: 0.4777\n",
      "Epoch 3/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 1.1388 - accuracy: 0.4777\n",
      "Epoch 4/45\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 1.1167 - accuracy: 0.4957\n",
      "Epoch 5/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 1.0925 - accuracy: 0.5021\n",
      "Epoch 6/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 1.0443 - accuracy: 0.5023\n",
      "Epoch 7/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 1.0044 - accuracy: 0.5024\n",
      "Epoch 8/45\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.9663 - accuracy: 0.5079\n",
      "Epoch 9/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.9501 - accuracy: 0.5215\n",
      "Epoch 10/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.9162 - accuracy: 0.5355\n",
      "Epoch 11/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 1.0810 - accuracy: 0.4958\n",
      "Epoch 12/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.9470 - accuracy: 0.5236\n",
      "Epoch 13/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.9508 - accuracy: 0.5232\n",
      "Epoch 14/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.8817 - accuracy: 0.5609\n",
      "Epoch 15/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.8384 - accuracy: 0.5938\n",
      "Epoch 16/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.8129 - accuracy: 0.6012\n",
      "Epoch 17/45\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.7845 - accuracy: 0.6126\n",
      "Epoch 18/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.7540 - accuracy: 0.6332\n",
      "Epoch 19/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.7251 - accuracy: 0.6444\n",
      "Epoch 20/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.7185 - accuracy: 0.6495\n",
      "Epoch 21/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.7467 - accuracy: 0.6414\n",
      "Epoch 22/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.6326 - accuracy: 0.6983\n",
      "Epoch 23/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.6320 - accuracy: 0.7000\n",
      "Epoch 24/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.6875 - accuracy: 0.6686\n",
      "Epoch 25/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.5712 - accuracy: 0.7275\n",
      "Epoch 26/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.5520 - accuracy: 0.7383\n",
      "Epoch 27/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.6424 - accuracy: 0.7037\n",
      "Epoch 28/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.5415 - accuracy: 0.7479\n",
      "Epoch 29/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.5375 - accuracy: 0.7467\n",
      "Epoch 30/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.5192 - accuracy: 0.7541\n",
      "Epoch 31/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.4716 - accuracy: 0.7816\n",
      "Epoch 32/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.4609 - accuracy: 0.7893\n",
      "Epoch 33/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.4736 - accuracy: 0.7803\n",
      "Epoch 34/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.4652 - accuracy: 0.7878\n",
      "Epoch 35/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.4276 - accuracy: 0.8025\n",
      "Epoch 36/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.4277 - accuracy: 0.8034\n",
      "Epoch 37/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3986 - accuracy: 0.8233\n",
      "Epoch 38/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3871 - accuracy: 0.8300\n",
      "Epoch 39/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3927 - accuracy: 0.8193\n",
      "Epoch 40/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3731 - accuracy: 0.8343\n",
      "Epoch 41/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.3611 - accuracy: 0.8357\n",
      "Epoch 42/45\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.3676 - accuracy: 0.8393\n",
      "Epoch 43/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3480 - accuracy: 0.8453\n",
      "Epoch 44/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3387 - accuracy: 0.8495\n",
      "Epoch 45/45\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.3152 - accuracy: 0.8619\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7561 - accuracy: 0.6452\n",
      "Dataset KAUG17 already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t\"bibitex\": \"@misc{key,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {Gear datasets},\n",
      "\t\thowpublished = {\\url{https://www.kau-sdol.com/kaug}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\",\n",
      "You can download the dataset manually from:  https://www.kau-sdol.com/kaug\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 60.85it/s]\n",
      "INFO:root:Read in 0.6400821208953857 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: vibration,unit,fault\n",
      "INFO:root:Train shape: (2800000, 3)\n",
      "INFO:root:Val shape: (1600000, 3)\n",
      "INFO:root:Test shape: (1800000, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "22/22 [==============================] - 2s 41ms/step - loss: 1.0981 - accuracy: 0.3411 - val_loss: 1.1003 - val_accuracy: 0.3801\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 1.0946 - accuracy: 0.3706 - val_loss: 1.0967 - val_accuracy: 0.4038\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 1.0893 - accuracy: 0.4029 - val_loss: 1.1038 - val_accuracy: 0.3654\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 1.0794 - accuracy: 0.4062 - val_loss: 1.1195 - val_accuracy: 0.3468\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 1.0695 - accuracy: 0.4179 - val_loss: 1.0826 - val_accuracy: 0.3686\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 1.0579 - accuracy: 0.4227 - val_loss: 1.1369 - val_accuracy: 0.2942\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 1.0582 - accuracy: 0.4088 - val_loss: 1.1166 - val_accuracy: 0.3231\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 1.0440 - accuracy: 0.4223 - val_loss: 1.0824 - val_accuracy: 0.3769\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 1.0396 - accuracy: 0.4183 - val_loss: 1.1104 - val_accuracy: 0.3205\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 1.0457 - accuracy: 0.4132 - val_loss: 1.0550 - val_accuracy: 0.3692\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 1.0337 - accuracy: 0.4242 - val_loss: 1.0702 - val_accuracy: 0.3769\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 1.0296 - accuracy: 0.4220 - val_loss: 1.0757 - val_accuracy: 0.3705\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 1.0270 - accuracy: 0.4289 - val_loss: 1.0488 - val_accuracy: 0.3974\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 1.0298 - accuracy: 0.4286 - val_loss: 1.0422 - val_accuracy: 0.4981\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 1.0203 - accuracy: 0.4388 - val_loss: 1.0363 - val_accuracy: 0.5019\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 1.0158 - accuracy: 0.4440 - val_loss: 1.0109 - val_accuracy: 0.5295\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.9981 - accuracy: 0.4755 - val_loss: 1.0720 - val_accuracy: 0.3577\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.9937 - accuracy: 0.4802 - val_loss: 0.9832 - val_accuracy: 0.5385\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.9982 - accuracy: 0.4850 - val_loss: 1.0052 - val_accuracy: 0.5186\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.9936 - accuracy: 0.4890 - val_loss: 0.9777 - val_accuracy: 0.5135\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.9910 - accuracy: 0.4670 - val_loss: 1.0023 - val_accuracy: 0.5090\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.9898 - accuracy: 0.4817 - val_loss: 0.9786 - val_accuracy: 0.5244\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.9867 - accuracy: 0.4857 - val_loss: 0.9794 - val_accuracy: 0.5353\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.9873 - accuracy: 0.4758 - val_loss: 1.0013 - val_accuracy: 0.5160\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.9873 - accuracy: 0.4832 - val_loss: 1.0265 - val_accuracy: 0.4673\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.9838 - accuracy: 0.4894 - val_loss: 0.9932 - val_accuracy: 0.5295\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.9887 - accuracy: 0.4718 - val_loss: 1.0084 - val_accuracy: 0.4942\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.9841 - accuracy: 0.4769 - val_loss: 1.0217 - val_accuracy: 0.4571\n",
      "Dataset KAUG17 already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t\"bibitex\": \"@misc{key,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {Gear datasets},\n",
      "\t\thowpublished = {\\url{https://www.kau-sdol.com/kaug}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\",\n",
      "You can download the dataset manually from:  https://www.kau-sdol.com/kaug\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 66.10it/s]\n",
      "INFO:root:Read in 0.5846197605133057 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: vibration,unit,fault\n",
      "INFO:root:Train shape: (3000000, 3)\n",
      "INFO:root:Val shape: (1400000, 3)\n",
      "INFO:root:Test shape: (1800000, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23/23 [==============================] - 2s 44ms/step - loss: 1.0983 - accuracy: 0.3533 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0956 - accuracy: 0.3902 - val_loss: 1.0963 - val_accuracy: 0.3055\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0867 - accuracy: 0.3807 - val_loss: 1.1095 - val_accuracy: 0.2857\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 1.0803 - accuracy: 0.3815 - val_loss: 1.0740 - val_accuracy: 0.3531\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 1.0687 - accuracy: 0.3699 - val_loss: 1.0638 - val_accuracy: 0.3326\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 1.0552 - accuracy: 0.3962 - val_loss: 1.0679 - val_accuracy: 0.3297\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0493 - accuracy: 0.3822 - val_loss: 1.0444 - val_accuracy: 0.4535\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0454 - accuracy: 0.3802 - val_loss: 1.0470 - val_accuracy: 0.4147\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 1.0456 - accuracy: 0.3938 - val_loss: 1.0398 - val_accuracy: 0.4689\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0421 - accuracy: 0.3938 - val_loss: 1.0418 - val_accuracy: 0.3956\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0350 - accuracy: 0.3959 - val_loss: 1.0455 - val_accuracy: 0.3773\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0401 - accuracy: 0.4010 - val_loss: 1.0384 - val_accuracy: 0.4425\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0302 - accuracy: 0.4000 - val_loss: 1.0335 - val_accuracy: 0.4674\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0257 - accuracy: 0.4123 - val_loss: 1.0458 - val_accuracy: 0.3729\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.0193 - accuracy: 0.4109 - val_loss: 1.0317 - val_accuracy: 0.4601\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.0184 - accuracy: 0.4222 - val_loss: 1.0253 - val_accuracy: 0.4476\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0109 - accuracy: 0.4315 - val_loss: 1.0312 - val_accuracy: 0.4491\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0111 - accuracy: 0.4188 - val_loss: 1.0264 - val_accuracy: 0.4249\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.9980 - accuracy: 0.4448 - val_loss: 1.0280 - val_accuracy: 0.4249\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9970 - accuracy: 0.4530 - val_loss: 1.0342 - val_accuracy: 0.4308\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9875 - accuracy: 0.4814 - val_loss: 1.0070 - val_accuracy: 0.4777\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9773 - accuracy: 0.5125 - val_loss: 1.0108 - val_accuracy: 0.4689\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9802 - accuracy: 0.4968 - val_loss: 1.0120 - val_accuracy: 0.4689\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9777 - accuracy: 0.5128 - val_loss: 1.0031 - val_accuracy: 0.4762\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9727 - accuracy: 0.5156 - val_loss: 1.0195 - val_accuracy: 0.4645\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9742 - accuracy: 0.5152 - val_loss: 1.0523 - val_accuracy: 0.4410\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9747 - accuracy: 0.5255 - val_loss: 1.0059 - val_accuracy: 0.4791\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9654 - accuracy: 0.5203 - val_loss: 1.0048 - val_accuracy: 0.4703\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9712 - accuracy: 0.5173 - val_loss: 1.0359 - val_accuracy: 0.4586\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9620 - accuracy: 0.5296 - val_loss: 1.0466 - val_accuracy: 0.4571\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9693 - accuracy: 0.5145 - val_loss: 1.0175 - val_accuracy: 0.4601\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9744 - accuracy: 0.5094 - val_loss: 1.0100 - val_accuracy: 0.4645\n",
      "Dataset KAUG17 already downloaded and extracted\n",
      "Remember to cite the original publisher dataset:\n",
      "\t\"bibitex\": \"@misc{key,\n",
      "\t\tauthor = {},\n",
      "\t\ttitle = {Gear datasets},\n",
      "\t\thowpublished = {\\url{https://www.kau-sdol.com/kaug}},\n",
      "\t\tyear = {},\n",
      "\t\tnote = {[Accessed 08-04-2024]},\n",
      "\t}\",\n",
      "You can download the dataset manually from:  https://www.kau-sdol.com/kaug\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 70.47it/s]\n",
      "INFO:root:Read in 0.5520684719085693 seconds\n",
      "INFO:root:It is possible stratified split? True\n",
      "INFO:root:Read 3 sets: train,val,test\n",
      "INFO:root:Columns: vibration,unit,fault\n",
      "INFO:root:Train shape: (3000000, 3)\n",
      "INFO:root:Val shape: (1400000, 3)\n",
      "INFO:root:Test shape: (1800000, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23/23 [==============================] - 2s 39ms/step - loss: 1.0972 - accuracy: 0.3895 - val_loss: 1.1164 - val_accuracy: 0.2857\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0804 - accuracy: 0.3997 - val_loss: 1.1335 - val_accuracy: 0.2857\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0782 - accuracy: 0.3997 - val_loss: 1.1416 - val_accuracy: 0.2857\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0739 - accuracy: 0.4000 - val_loss: 1.1354 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.0723 - accuracy: 0.4055 - val_loss: 1.1153 - val_accuracy: 0.3348\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0706 - accuracy: 0.4198 - val_loss: 1.1085 - val_accuracy: 0.3436\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0628 - accuracy: 0.4342 - val_loss: 1.1228 - val_accuracy: 0.3385\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0475 - accuracy: 0.4516 - val_loss: 1.0867 - val_accuracy: 0.3407\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0329 - accuracy: 0.4465 - val_loss: 1.0925 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0275 - accuracy: 0.4653 - val_loss: 1.0772 - val_accuracy: 0.3414\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.0227 - accuracy: 0.4653 - val_loss: 1.0743 - val_accuracy: 0.3853\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0247 - accuracy: 0.4595 - val_loss: 1.0645 - val_accuracy: 0.3912\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0154 - accuracy: 0.4797 - val_loss: 1.0906 - val_accuracy: 0.3685\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 1.0114 - accuracy: 0.4742 - val_loss: 1.0814 - val_accuracy: 0.3656\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0131 - accuracy: 0.4550 - val_loss: 1.0819 - val_accuracy: 0.3612\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.0006 - accuracy: 0.4937 - val_loss: 1.0577 - val_accuracy: 0.3839\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 1.0000 - accuracy: 0.4773 - val_loss: 1.0635 - val_accuracy: 0.3744\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9933 - accuracy: 0.4909 - val_loss: 1.0445 - val_accuracy: 0.3707\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9837 - accuracy: 0.4995 - val_loss: 1.0465 - val_accuracy: 0.4176\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.9771 - accuracy: 0.5067 - val_loss: 1.0592 - val_accuracy: 0.4110\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9715 - accuracy: 0.5125 - val_loss: 1.0591 - val_accuracy: 0.4117\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9766 - accuracy: 0.4998 - val_loss: 1.0486 - val_accuracy: 0.4125\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.9736 - accuracy: 0.5029 - val_loss: 1.0273 - val_accuracy: 0.4249\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.9657 - accuracy: 0.5108 - val_loss: 1.0279 - val_accuracy: 0.4154\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9726 - accuracy: 0.5036 - val_loss: 1.0665 - val_accuracy: 0.4007\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9751 - accuracy: 0.4950 - val_loss: 1.0489 - val_accuracy: 0.4110\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9643 - accuracy: 0.5138 - val_loss: 1.0359 - val_accuracy: 0.4227\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9637 - accuracy: 0.5145 - val_loss: 1.0185 - val_accuracy: 0.4293\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9710 - accuracy: 0.5056 - val_loss: 1.0263 - val_accuracy: 0.3817\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.9659 - accuracy: 0.5135 - val_loss: 1.0441 - val_accuracy: 0.4168\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.9600 - accuracy: 0.5169 - val_loss: 1.0430 - val_accuracy: 0.4168\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9713 - accuracy: 0.5060 - val_loss: 1.0507 - val_accuracy: 0.4161\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.9679 - accuracy: 0.5043 - val_loss: 1.0077 - val_accuracy: 0.4469\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9572 - accuracy: 0.5248 - val_loss: 1.0230 - val_accuracy: 0.4300\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9590 - accuracy: 0.5268 - val_loss: 1.0135 - val_accuracy: 0.4762\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.9700 - accuracy: 0.5056 - val_loss: 1.0161 - val_accuracy: 0.4755\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9640 - accuracy: 0.5262 - val_loss: 1.0412 - val_accuracy: 0.4527\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9618 - accuracy: 0.5234 - val_loss: 1.0212 - val_accuracy: 0.4689\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9550 - accuracy: 0.5381 - val_loss: 1.0316 - val_accuracy: 0.4703\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.9533 - accuracy: 0.5429 - val_loss: 1.0291 - val_accuracy: 0.4696\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.9583 - accuracy: 0.5337 - val_loss: 1.0299 - val_accuracy: 0.4564\n",
      "Epoch 1/3\n",
      "34/34 [==============================] - 2s 24ms/step - loss: 1.0968 - accuracy: 0.3677\n",
      "Epoch 2/3\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 1.0915 - accuracy: 0.3680\n",
      "Epoch 3/3\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 1.0884 - accuracy: 0.3999\n",
      "Epoch 1/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0765 - accuracy: 0.3904\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0545 - accuracy: 0.3946\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 1.0440 - accuracy: 0.4159\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0423 - accuracy: 0.4075\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0332 - accuracy: 0.4343\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0228 - accuracy: 0.4543\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0205 - accuracy: 0.4366\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0160 - accuracy: 0.4485\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 1.0000 - accuracy: 0.4867\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9828 - accuracy: 0.5070\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9866 - accuracy: 0.4890\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9847 - accuracy: 0.5014\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9856 - accuracy: 0.4974\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9788 - accuracy: 0.5054\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.9773 - accuracy: 0.5044\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9770 - accuracy: 0.5047\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9757 - accuracy: 0.5163\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9729 - accuracy: 0.5166\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9773 - accuracy: 0.5058\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9783 - accuracy: 0.5093\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9717 - accuracy: 0.5156\n",
      "Epoch 22/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9696 - accuracy: 0.5189\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9726 - accuracy: 0.5168\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9723 - accuracy: 0.5163\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.9742 - accuracy: 0.5096\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9731 - accuracy: 0.5203\n",
      "Epoch 27/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9719 - accuracy: 0.5110\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9718 - accuracy: 0.5117\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9680 - accuracy: 0.5186\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9708 - accuracy: 0.5119\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.9443 - accuracy: 0.5373\n"
     ]
    }
   ],
   "source": [
    "# List of datasets to process\n",
    "DATASETS = ['NMILL', 'CWRU', 'KAUG17']\n",
    "\n",
    "# Dictionary to store predictions and results for each dataset\n",
    "predictions = {}\n",
    "\n",
    "# Loop through each dataset\n",
    "for dataset in DATASETS:\n",
    "    # Load the dataset using the Dataset class\n",
    "    ds = datasets.Dataset(dataset)\n",
    "    \n",
    "    # Access the Remaining Useful Life (RUL) task associated with the dataset\n",
    "    target = ds.tasks[0].meta['target']\n",
    "    task = ds[target]\n",
    "    \n",
    "    # Configure the task settings\n",
    "    task.folds = 3  # Number of cross-validation folds\n",
    "    task.preprocess = MinMaxScaler()  # Apply MinMaxScaler as a preprocessing step\n",
    "    \n",
    "    # Determine the subsequence length (TS) for windowing the data\n",
    "    TS = min(1024, ds[target].meta['min_ts_len'] // 20)\n",
    "    \n",
    "    # List to store the number of epochs for early stopping across folds\n",
    "    ea_epochs = []\n",
    "    \n",
    "    # Get the unit identifier for grouping data\n",
    "    unit_id = ds[target].meta['identifier']\n",
    "    \n",
    "    # Define the number of epochs for training\n",
    "    EPOCHS = 100\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for i in range(task.folds):\n",
    "        # Retrieve the data for the current fold (training, validation, test sets)\n",
    "        data = task[i]\n",
    "        X_train, X_val, X_test = data['train'], data['val'], data['test']\n",
    "        \n",
    "        # Calculate the minimum signal length across training, validation, and test sets\n",
    "        signal_sizes = [\n",
    "            X_train.groupby(unit_id).size().min(),\n",
    "            X_val.groupby(unit_id).size().min(),\n",
    "            X_test.groupby(unit_id).size().min()\n",
    "        ]\n",
    "        signal_max_length = min(np.min(signal_sizes), 20000000)\n",
    "        \n",
    "        # Prepare the data for training and validation using windowing\n",
    "        X_train, Y_train = window_split(X_train, unit_id, ds[target].meta['features'], target, TS, signal_max_length)\n",
    "        X_val, Y_val = window_split(X_val, unit_id, ds[target].meta['features'], target, TS, signal_max_length)\n",
    "        \n",
    "        # Train the model using the training data and validate on validation data\n",
    "        results, model = train((X_train, Y_train), len(task.meta['target_labels']), \n",
    "                               EPOCHS, es=True, validation_data=(X_val, Y_val))\n",
    "        \n",
    "        # Record the number of epochs run before early stopping\n",
    "        ea_epochs.append(len(results.history['loss']))\n",
    "    \n",
    "    # Train the final model using all training and validation data\n",
    "    train_data = np.concatenate((X_train, X_val)), np.concatenate((Y_train, Y_val))\n",
    "    results, model = train(train_data, len(task.meta['target_labels']), int(np.mean(ea_epochs)), \n",
    "                           es=False, validation_data=None)\n",
    "    \n",
    "    # Evaluate the model on one specific unit of the test set\n",
    "    X_aux, Y_aux = window_split(X_test, unit_id, ds[target].meta['features'], target, TS, signal_max_length)\n",
    "    Y_pred = model.predict(X_aux)\n",
    "    \n",
    "    # Evaluate the model on the entire test set\n",
    "    X_test, Y_test = window_split(X_test, unit_id, ds[target].meta['features'], target, TS, signal_max_length)\n",
    "    results = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    # Store the predictions and results for the current dataset\n",
    "    predictions[dataset] = [Y_aux, Y_pred, ds[target].meta['target_labels']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd9439-63cb-4a7a-8eb7-44b3aa9460d8",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Generates side-by-side confusion matrices for each dataset. Each plot also displays the F1 Score, obtained in the full test set, in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "170daddc-f13b-43b9-ad95-86905c257e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Create a figure with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Iterate over datasets and axes\n",
    "for ax, dataset in zip(axes, DATASETS):\n",
    "    # Extract true values, predictions, and target labels\n",
    "    Y_aux, Y_pred, target_labels = predictions[dataset]\n",
    "    \n",
    "    # Convert probabilities to class predictions\n",
    "    Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(Y_aux, Y_pred_classes, average='macro')\n",
    "    \n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(Y_aux, Y_pred_classes)\n",
    "    \n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_labels)\n",
    "    disp.plot(ax=ax, colorbar=False)\n",
    "    \n",
    "    # Add title and F1 score to the plot\n",
    "    ax.set_title(f'{dataset} (F1: {f1:.2f})')\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('diag_example.svg')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
